# Module 10: Prompt Injection and Security

## Objective
Understand the risks of prompt injection and how to mitigate them.

## Contents
- Explanation of prompt injection attacks.
- Best practices for securing LLM applications.
- Testing prompts for vulnerabilities.

## Exercises
1. **Prompt Injection Simulation:**
   - Craft inputs that could lead to prompt injection.
   - Observe how the LLM responds and identify weaknesses.
2. **Mitigation Strategies:**
   - Implement input validation and sanitization.
   - Use guardrails or prompt templates to enforce boundaries.

## Notes
There is currently no content in this module, the exercise is open to the user.
Combine the knowledge you've gathered over the workshop and play around with a bot that stores a password.
Attempt to use prompt injection to get past your defenses, and keep iterating on your security measures.

Do not simply use the Spring SafeGuardAdvisor, to understand prompt injection start from scratch to appreciate the risks and how to mitigate them.
